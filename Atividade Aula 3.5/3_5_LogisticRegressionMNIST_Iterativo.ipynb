{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.5-LogisticRegressionMNIST-Iterativo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3td_pl4mvQD"
      },
      "source": [
        "# Regressão Softmax com dados do MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtkJT-FtmvQE"
      },
      "source": [
        "## Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF-ByQKJmvQF"
      },
      "source": [
        "O objetivo deste notebook é ilustrar o uso de praticamente a mesma rede desenvolvida para a classificação das flores Íris, porém agora com o problema de classificação de dígitos manuscritos utilizando o dataset MNIST.\n",
        "As principais diferenças são:\n",
        "- tipo do dado, agora imagem com muito atributos: 28 x 28 pixels\n",
        "- número de amostras, muito maior, 60 mil\n",
        "Neste exercício será possível a interpretação do significado dos parâmetros treinados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGsYwaRemvQH"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO0SMXOT_R3-",
        "outputId": "55e2ea49-c7c5-4259-ccef-a7797bef6200"
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "#!pip install numpy==1.15.0\n",
        "!pip install -q install wheel==0.34.2 setuptools\n",
        "\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "print(get_abbr_impl())\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "#https://download.pytorch.org/whl/cpu/torch-0.4.1.post2-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1.post2-{platform}-linux_x86_64.whl torchvision==0.2.1\n",
        "\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp\n",
            "\u001b[31m  ERROR: HTTP error 403 while getting http://download.pytorch.org/whl/cpu/torch-0.4.1.post2-cp310-cp310-linux_x86_64.whl\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not install requirement torch==0.4.1.post2 from http://download.pytorch.org/whl/cpu/torch-0.4.1.post2-cp310-cp310-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cpu/torch-0.4.1.post2-cp310-cp310-linux_x86_64.whl for URL http://download.pytorch.org/whl/cpu/torch-0.4.1.post2-cp310-cp310-linux_x86_64.whl\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:50.097111",
          "start_time": "2017-11-24T15:44:48.915046"
        },
        "id": "JeBH-PI4mvQI"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLEq8nmUmvQL"
      },
      "source": [
        "## Carregamento dos dados do MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ueXR4zIo5wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd9a0fb-5b6a-4b81-be8b-b038ee8ef765"
      },
      "source": [
        "! git clone https://github.com/vcasadei/MNIST.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MNIST'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Total 10 (delta 0), reused 0 (delta 0), pack-reused 10\u001b[K\n",
            "Receiving objects: 100% (10/10), 11.01 MiB | 13.92 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Updating files: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:50.638218",
          "start_time": "2017-11-24T15:44:50.098808"
        },
        "id": "xZWPIWlumvQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853128d1-c4f1-460f-f6e2-87af1a616385"
      },
      "source": [
        "dataset_dir = 'MNIST/'\n",
        "\n",
        "x_train, y_train = torch.load(dataset_dir + 'processed/training.pt')\n",
        "\n",
        "print(\"Amostras de treinamento:\", x_train.size(0))\n",
        "\n",
        "print(\"\\nDimensões dos dados das imagens:   \", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels:\", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:        \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:      \", type(y_train))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras de treinamento: 60000\n",
            "\n",
            "Dimensões dos dados das imagens:    torch.Size([60000, 28, 28])\n",
            "Valores mínimo e máximo dos pixels: tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n",
            "Tipo dos dados das imagens:         <class 'torch.Tensor'>\n",
            "Tipo das classes das imagens:       <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR2L0QQgmvQU"
      },
      "source": [
        "### Carregamento, normalização e seleção dos dados do MNIST\n",
        "\n",
        "Neste exemplo utilizaremos apenas 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:50.895668",
          "start_time": "2017-11-24T15:44:50.640110"
        },
        "id": "C9Rh7wRemvQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa9703f-33e6-4549-b25f-5e67c8a20dd8"
      },
      "source": [
        "x_train = x_train.float()\n",
        "\n",
        "x_train = x_train / 255.\n",
        "\n",
        "if True:\n",
        "    n_samples_train = 1000\n",
        "\n",
        "    x_train = x_train[:n_samples_train]\n",
        "    y_train = y_train[:n_samples_train]\n",
        "\n",
        "print(\"Amostras de treinamento:\", x_train.size(0))\n",
        "\n",
        "print(\"\\nDimensões dos dados das imagens:   \", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels:\", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:        \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:      \", type(y_train))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras de treinamento: 1000\n",
            "\n",
            "Dimensões dos dados das imagens:    torch.Size([1000, 28, 28])\n",
            "Valores mínimo e máximo dos pixels: tensor(0.) tensor(1.)\n",
            "Tipo dos dados das imagens:         <class 'torch.Tensor'>\n",
            "Tipo das classes das imagens:       <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UtzmsQimvQa"
      },
      "source": [
        "### Visualizando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T16:32:19.474568",
          "start_time": "2017-11-24T16:32:19.207270"
        },
        "id": "gFG0qpODmvQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "260b9cc9-e4b8-4e16-d43c-a26cfb1ed899"
      },
      "source": [
        "n_samples = 24\n",
        "\n",
        "# cria um grid com as imagens\n",
        "grid = torchvision.utils.make_grid(x_train[:n_samples].unsqueeze(1), pad_value=1.0, padding=1)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
        "plt.axis('off')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torchvision' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-04d1f43afec6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# cria um grid com as imagens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075sVFBZmvQe"
      },
      "source": [
        "### Visualizando uma imagem com o matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:51.413232",
          "start_time": "2017-11-24T15:44:51.251376"
        },
        "id": "3W2NpeW0mvQg"
      },
      "source": [
        "image  = x_train[0]\n",
        "target = y_train[0]\n",
        "\n",
        "plt.imshow(image.numpy().reshape(28,28), cmap='gray')\n",
        "print('class:', target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU-PzteEmvQj"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:51.419287",
          "start_time": "2017-11-24T15:44:51.415065"
        },
        "id": "VKMngBWzmvQk"
      },
      "source": [
        "model = torch.nn.Linear(28*28, 10) # 28*28 atributos de entrada e 10 neurônios na sáida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzvpr1u6mvQo"
      },
      "source": [
        "### Testando um predict com poucas amostras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiiO8WDAmvQq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIIeicyGmvQs"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSfqKNW2mvQt"
      },
      "source": [
        "### Inicialização dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:51.425768",
          "start_time": "2017-11-24T15:44:51.420825"
        },
        "id": "I9W3OFvomvQu"
      },
      "source": [
        "epochs = 5\n",
        "learningRate = 0.5\n",
        "\n",
        "# Utilizaremos CrossEntropyLoss como função de perda\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Gradiente descendente\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlNgV_pgmvQx"
      },
      "source": [
        "### Visualização do grafo computacional da perda (loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ycGDyoWjMoR"
      },
      "source": [
        "!pip install graphviz\n",
        "!pip install git+https://github.com/szagoruyko/pytorchviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T16:28:18.101867",
          "start_time": "2017-11-24T16:28:18.062312"
        },
        "id": "oYPRIePImvQz"
      },
      "source": [
        "y_pred = model(Variable(x_train.view(-1,28*28)))\n",
        "loss = criterion(y_pred, Variable(y_train))\n",
        "from torchviz import make_dot, make_dot_from_trace\n",
        "p = make_dot(loss, dict(model.named_parameters()))\n",
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq2yq8qAmvQ2"
      },
      "source": [
        "### Laço de treinamento dos pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:51.678678",
          "start_time": "2017-11-24T15:44:51.427695"
        },
        "id": "HPUUNKXxmvQ3"
      },
      "source": [
        "from IPython import display\n",
        "import numpy\n",
        "a = 5\n",
        "losses = []\n",
        "zs = []\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "try:\n",
        "    for i in range(epochs):\n",
        "        # Transforma a entrada para uma dimensão\n",
        "        inputs = Variable(x_train.view(-1, 28 * 28))\n",
        "        # Predict da rede\n",
        "        outputs = model(inputs)\n",
        "        zs.append(outputs[1].detach().numpy())\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, Variable(y_train))\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.data[0])\n",
        "        weights_d = model.weight.data[4].numpy().reshape(28,28)\n",
        "        weights_g = model.weight.grad.data[4].numpy().reshape(28,28)\n",
        "        ww = np.concatenate((weights_d,weights_g),1)\n",
        "        plt.imshow(ww.reshape((28,28*2)),cmap = 'gray')\n",
        "        display.display(fig)\n",
        "        display.clear_output(wait=True)\n",
        "        input(i)\n",
        "\n",
        "        _, predicts = torch.max(outputs, 1)\n",
        "\n",
        "        y_pred = predicts.data\n",
        "        accuracy = (y_pred.numpy() == y_train.numpy()).mean()\n",
        "        print('Accuracy:', accuracy)\n",
        "        print(\"epoca: \" + str(i + 1))\n",
        "        print(\"perda: \" + str(loss.data[0].detach().numpy()))\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wbN-_fnmvQ7"
      },
      "source": [
        "model.weight.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:51.685301",
          "start_time": "2017-11-24T15:44:51.680419"
        },
        "id": "mPWKRc_gmvRH"
      },
      "source": [
        "print('Final loss:', loss.data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWIjRdCJmvRQ"
      },
      "source": [
        "### Visualizando gráfico de perda durante o treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:44:56.787741",
          "start_time": "2017-11-24T15:44:56.627754"
        },
        "id": "gwV8aFcbmvRR"
      },
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8og76PRmvRW"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIe0ngxWmvRY"
      },
      "source": [
        "### Acurácia tanto no conjunto de treinamento como no conjunto de testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:50:29.922115",
          "start_time": "2017-11-24T15:50:29.914004"
        },
        "id": "tlL-lfF5mvRZ"
      },
      "source": [
        "def predict(model, input_data):\n",
        "    outputs = model(Variable(input_data))\n",
        "    _, predicts = torch.max(outputs, 1)\n",
        "\n",
        "    return predicts.data\n",
        "\n",
        "y_pred = predict(model, x_train.view(-1, 28*28))\n",
        "accuracy = (y_pred.numpy() == y_train.numpy()).mean()\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvWz9qeDmvRc"
      },
      "source": [
        "### Matriz de confusão com dados de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T15:51:40.706177",
          "start_time": "2017-11-24T15:51:40.679474"
        },
        "id": "CqNe40IqmvRd"
      },
      "source": [
        "print('Matriz de confusão:')\n",
        "pd.crosstab(y_pred.numpy(), y_train.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjDGqb7mvRi"
      },
      "source": [
        "## Visualizando a matriz de pesos treinados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYuIu31KmvRj"
      },
      "source": [
        "Observe que a matriz de peso treinado para cada classe mostra a importância dos pesos associados aos caracteres de cada classe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T16:34:49.367135",
          "start_time": "2017-11-24T16:34:49.204452"
        },
        "id": "_QESuAB8mvRk"
      },
      "source": [
        "weights = model.state_dict()['weight']\n",
        "print('weights:', weights.shape)\n",
        "\n",
        "bias = model.state_dict()['bias']\n",
        "print('bias:   ', bias.shape)\n",
        "\n",
        "# Visualizando pesos da classe 3\n",
        "plt.imshow(weights[3, :].numpy().reshape((28,28)),cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE1B62KamvRp"
      },
      "source": [
        "### Visualizando os pesos de todas as classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T16:34:50.240218",
          "start_time": "2017-11-24T16:34:50.025515"
        },
        "id": "EHm39Pe_mvRp"
      },
      "source": [
        "# cria um grid com as imagens\n",
        "grid = torchvision.utils.make_grid(weights.view(-1, 1, 28, 28), normalize=True, pad_value=1.0, padding=1, nrow=10)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odqHBFclmvRt"
      },
      "source": [
        "### Diagrama da regressão softmax com visualização dos pesos W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKoDiM-mvRu"
      },
      "source": [
        "![alt text](http://casadei.io/images/RegressaoSoftmaxArgmaxNMIST.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0vTJyVbmvRv"
      },
      "source": [
        "# Atividades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl-7WEDMmvRw"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJDTuOrDmvRy"
      },
      "source": [
        "- 1) Na configuração da figura acima, mostre os valores de z0 até z9, os valores das probabilidades y_hat, após o softmax, quando a rede recebe como entrada a nona amostra que contém o manuscrito do dígito '4':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T16:34:53.969413",
          "start_time": "2017-11-24T16:34:53.805978"
        },
        "id": "Wir3kru7mvR0"
      },
      "source": [
        "image  = x_train[9]\n",
        "target = y_train[9]\n",
        "\n",
        "plt.imshow(image.numpy().reshape(28,28), cmap='gray')\n",
        "print('class:', target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn4GzfSYmvR5"
      },
      "source": [
        "- 2) Insira código no laço do treinamento para que no final de cada época,\n",
        "     seja impresso: o número da época e a perda e a acurácia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtZPs6M6mvR6"
      },
      "source": [
        "- 3) Insira código no laço do treinamento para visualização dos valores dos gradientes referentes à classe do dígito 4, no final de cada época."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import numpy\n",
        "a = 5\n",
        "losses = []\n",
        "zs = []\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "try:\n",
        "    for i in range(epochs):\n",
        "        # Transforma a entrada para uma dimensão\n",
        "        inputs = Variable(x_train.view(-1, 28 * 28))\n",
        "        # Predict da rede\n",
        "        outputs = model(inputs)\n",
        "        zs.append(outputs[1].detach().numpy())\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, Variable(y_train))\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.data[0])\n",
        "        weights_d = model.weight.data[4].numpy().reshape(28,28)\n",
        "        weights_g = model.weight.grad.data[4].numpy().reshape(28,28)\n",
        "        ww = np.concatenate((weights_d,weights_g),1)\n",
        "        plt.imshow(ww.reshape((28,28*2)),cmap = 'gray')\n",
        "        display.display(fig)\n",
        "        display.clear_output(wait=True)\n",
        "        input(i)\n",
        "\n",
        "        _, predicts = torch.max(outputs, 1)\n",
        "\n",
        "        y_pred = predicts.data\n",
        "        accuracy = (y_pred.numpy() == y_train.numpy()).mean()\n",
        "        print('Accuracy:', accuracy)\n",
        "        print(\"epoca: \" + str(i + 1))\n",
        "        print(\"perda: \" + str(loss.data[0].detach().numpy()))\n",
        "\n",
        "        plt.imshow(weights[4, :].numpy().reshape((28,28)),cmap = 'gray')\n",
        "        plt.show()\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "metadata": {
        "id": "yPCQ2TaBfa0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "WNYt_-zhmvR7"
      },
      "source": [
        "## Perguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "joaXY_W3mvR9"
      },
      "source": [
        "1. Qual é o shape da matriz de entrada na rede?\n",
        "R. [1000, 28, 28]\n",
        "2. Qual é o shape da saída da rede?\n",
        "R. [1000,10]\n",
        "3. Qual é o número total de parâmetros da rede, incluindo o bias?\n",
        "R.7850"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzWdNQ6PmvR9"
      },
      "source": [
        "# Aprendizados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJgiDZFWmvR_"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}